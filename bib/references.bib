% This file was created with JabRef 2.9.2.
% Encoding: Cp1252

@article{thompson1994treatment,
  title={Treatment approaches to bruxism.},
  author={Thompson, BA and Blount, BW and Krumholz, TS},
  journal={American family physician},
  volume={49},
  number={7},
  pages={1617--1622},
  year={1994}
}

@article{shetty2010bruxism,
  title={Bruxism: a literature review},
  author={Shetty, Shilpa and Pitti, Varun and Satish Babu, CL and Surendra Kumar, GP and Deepthi, BC},
  journal={The Journal of Indian prosthodontic society},
  volume={10},
  number={3},
  pages={141--148},
  year={2010},
  publisher={Springer}
}

@inproceedings{bondareva2021earables,
  title={Earables for Detection of Bruxism: a Feasibility Study},
  author={Bondareva, Erika and Hauksd{\'o}ttir, El{\'\i}n R{\'o}s and Mascolo, Cecilia},
  booktitle={Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers},
  pages={146--151},
  year={2021}
}

@inproceedings{lotfi2020comparison,
  title={A comparison between audio and IMU data to detect chewing events based on an earable device},
  author={Lotfi, Roya and Tzanetakis, George and Eskicioglu, Rasit and Irani, Pourang},
  booktitle={Proceedings of the 11th Augmented Human International Conference},
  pages={1--8},
  year={2020}
}

@inproceedings{Knierim2021,
   abstract = {Bruxism is associated with multiple health issues and affects millions of people worldwide. To enable effective interventions, precise, easy-to-use and unobtrusive detection systems are required. Unfortunately, especially for daytime bruxism, such systems still rely on electrodes placed on the face, recording diaries, and manual algorithm tuning. In this work, we present a novel approach for bruxing event detection using comfortable and inconspicuous around-the-ear sensors (cEEGrids) as a form of distal EMG-based measurement. Using Random Forest classifiers on laboratory experiment data, promising F1-scores (up to 0.9) are found for the detection of bruxing events in contrast to a variety of other facial muscle activity events. Thereby, a promising new alternative for feasible awake bruxism detection is demonstrated.},
   author = {Michael Thomas Knierim and Max Schemmer and Dominik Woehler},
   doi = {10.1007/978-3-030-80091-8_4},
   isbn = {9783030800901},
   issn = {23673389},
   journal = {Lecture Notes in Networks and Systems},
   keywords = {Bruxism,Classification,Distal EMG,Machine learning,cEEGrid},
   pages = {26-33},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Detecting Daytime Bruxism Through Convenient and Wearable Around-the-Ear Electrodes},
   volume = {275},
   year = {2021},
}

@inproceedings{Ando2017,
   abstract = {We present a jaw, face, or head movement (face-related movement) recognition system called CanalSense. It recognizes face-related movements using barometers embedded in earphones. We find that face-related movements change air pressure inside the ear canals, which shows characteristic changes depending on the type and degree of the movement. We also find that such characteristic changes can be used to recognize face-related movements. We conduct an experiment to measure the accuracy of recognition. As a result, random forest shows per-user recognition accuracies of 87.6% for eleven face-related movements and 87.5% for four Open Mouth levels.},
   author = {Toshiyuki Ando and Yuki Kubo and Buntarou Shizuki and Shin Takahashi},
   doi = {10.1145/3126594.3126649},
   isbn = {9781450349819},
   journal = {UIST 2017 - Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
   keywords = {Barometer,Earphones,Eyes-free,Facial movement,Hands-free,Head movement,Jaw movement,Mouth movement,Outer ear interface,Wearable computing},
   month = {10},
   pages = {679-689},
   publisher = {Association for Computing Machinery, Inc},
   title = {CanalSense: Face-related movement recognition system based on sensing air pressure in ear canals},
   year = {2017},
}

@inproceedings{Prakash2020,
   abstract = {This paper finds that actions of the teeth, namely tapping and sliding , produce vibrations in the jaw and skull. These vibrations are strong enough to propagate to the edge of the face and produce vi-bratory signals at an earphone. By re-tasking the earphone speaker as an input transducer-a software modification in the sound card-we are able to sense teeth-related gestures across various models of ear/headphones. In fact, by analyzing the signals at the two earphones, we show the feasibility of also localizing teeth gestures, resulting in a human-to-machine interface. Challenges range from coping with weak signals, distortions due to different teeth compositions , lack of timing resolution, spectral dispersion, etc. We address these problems with a sequence of sensing techniques, resulting in the ability to detect 6 distinct gestures in real-time. Results from 18 volunteers exhibit robustness, even though our system-EarSense-does not depend on per-user training. Importantly, EarSense also remains robust in the presence of concurrent user activities, like walking, nodding, cooking and cycling. Our ongoing work is fo-cused on detecting teeth gestures even while music is being played in the earphone; once that problem is solved, we believe EarSense could be even more compelling. CCS CONCEPTS • Human-centered computing → Interaction techniques; • Information systems → Mobile information processing systems; • Computer systems organization → Embedded and cyber-physical systems.},
   author = {Jay Prakash and Zhijian Yang and Yu-Lin Wei and Haitham Hassanieh and Romit Roy Choudhury},
   doi = {10.1145/3372224.3419197},
   month = {9},
   pages = {1-13},
   publisher = {Association for Computing Machinery (ACM)},
   title = {EarSense},
   year = {2020},
}

@inproceedings{Sun2021,
   abstract = {Teeth gestures become an alternative input modality for different situations and accessibility purposes. In this paper, we present TeethTap, a novel eyes-free and hands-free input technique, which can recognize up to 13 discrete teeth tapping gestures. TeethTap adopts a wearable 3D printed earpiece with an IMU sensor and a contact microphone behind both ears, which works in tandem to detect jaw movement and sound data, respectively. TeethTap uses a support vector machine to classify gestures from noise by fusing acoustic and motion data, and implements K-Nearest-Neighbor (KNN) with a Dynamic Time Warping (DTW) distance measurement using motion data for gesture classification. A user study with 11 participants demonstrated that TeethTap could recognize 13 gestures with a real-time classification accuracy of 90.9\% in a laboratory environment. We further uncovered the accuracy differences on different teeth gestures when having sensors on single vs. both sides. Moreover, we explored the activation gesture under real-world environments, including eating, speaking, walking and jumping. Based on our findings, we further discussed potential applications and practical challenges of integrating TeethTap into future devices.},
   author = {Wei Sun and Franklin Mingzhe Li and Benjamin Steeper and Songlin Xu and Feng Tian and Cheng Zhang},
   doi = {10.1145/3397481.3450645},
   isbn = {9781450380171},
   journal = {International Conference on Intelligent User Interfaces, Proceedings IUI},
   keywords = {Acoustic Sensing,Earpiece,Eyes-free Input,Hands-free Input,Motion Sensing,Teeth Gestures},
   month = {4},
   pages = {161-169},
   publisher = {Association for Computing Machinery},
   title = {TeethTap: Recognizing Discrete Teeth Gestures Using Motion and Acoustic Sensing on an Earpiece},
   year = {2021},
}

@article{Sonmezocak2021,
   abstract = {Bruxism is known as the rhythmical clenching of the lower jaw (mandibular) by the contraction of the masticatory muscles and parafunctional grinding of the teeth. It affects patients’ quality of life adversely due to tooth wear, pain, and fatigue in the jaw muscles. Recently, effective diagnosis methods that use electromyography, electrocardiography, and electroencephalography have been developed for bruxism. However, these methods are not economical since they require specialization and can be performed in clinical conditions. Although using surface electromyography signals alone is an economical solution, it is difficult to identify fatigue and parafunctional movements of the jaw muscles via electromyography signals due to peripheral effects. In this study, to achieve an accurate diagnosis of bruxism economically with only electromyography measurements, a new approach based on Autoregression and Shannon Entropies of Discrete Wavelet Transform Energy Spectra to identify jaw muscle activities and fatigue conditions is proposed. By using Artificial Neural Networks in the proposed model, bruxism activities can be detected most accurately.},
   author = {Temel Sonmezocak and Serkan Kurt},
   doi = {10.5755/j02.eie.28838},
   issn = {20295731},
   issue = {2},
   journal = {Elektronika ir Elektrotechnika},
   keywords = {Artificial intelligence,Autoregressive processes,Electromyography,Fatigue,Wavelet transform},
   pages = {11-21},
   publisher = {Kauno Technologijos Universitetas},
   title = {Detection of EMG signals by neural networks using autoregression and wavelet entropy for bruxism diagnosis},
   volume = {27},
   year = {2021},
}

@article{kawsar2018earables,
  title={Earables for personal-scale behavior analytics},
  author={Kawsar, Fahim and Min, Chulhong and Mathur, Akhil and Montanari, Allesandro},
  journal={IEEE Pervasive Computing},
  volume={17},
  number={3},
  pages={83--89},
  year={2018},
  publisher={IEEE}
}

@inproceedings{min2018exploring,
  title={Exploring audio and kinetic sensing on earable devices},
  author={Min, Chulhong and Mathur, Akhil and Kawsar, Fahim},
  booktitle={Proceedings of the 4th ACM Workshop on Wearable Systems and Applications},
  pages={5--10},
  year={2018}
}

 @misc{esense_ble_specification, 
  title={Esense Ble Specifications}, 
  howpublished={\url{https://www.esense.io/share/eSense-BLE-Specification.pdf}}
} 

 @misc{crook_2022, 
 title={Audacity}, 
 howpublished={\url{https://www.audacityteam.org/}},
 author={Crook, James}
 }
 
 @article{lundqvist1998karolinska,
  title={Karolinska directed emotional faces},
  author={Lundqvist, Daniel and Flykt, Anders and {\"O}hman, Arne},
  journal={Cognition and Emotion},
  year={1998}
}

@article{sabaneeff2017proposal,
  title={Proposal of surface electromyography signal acquisition protocols for masseter and temporalis muscles},
  author={Sabaneeff, Ana and Caldas, Luciana Duarte and Garcia, Marco Antonio Cavalcanti and Nojima, Matilde da Cunha Gon{\c{c}}alves},
  journal={Research on Biomedical Engineering},
  volume={33},
  pages={324--330},
  year={2017},
  publisher={SciELO Brasil}
}

@article{manfredini2013epidemiology,
  title={Epidemiology of bruxism in adults: a systematic review of the literature},
  author={Manfredini, Daniele and Winocur, Ephraim and Guarda-Nardini, Luca and Paesani, Daniel and Lobbezoo, Frank and others},
  journal={J Orofac Pain},
  volume={27},
  number={2},
  pages={99--110},
  year={2013}
}

@article{yap2016sleep,
  title={Sleep bruxism: Current knowledge and contemporary management},
  author={Yap, Adrian U and Chua, Ai Ping},
  journal={Journal of conservative dentistry: JCD},
  volume={19},
  number={5},
  pages={383},
  year={2016},
  publisher={Wolters Kluwer--Medknow Publications}
}

@article{smardz2019correlation,
  title={Correlation between sleep bruxism, stress, and depression—a polysomnographic study},
  author={Smardz, Joanna and Martynowicz, Helena and Wojakowska, Anna and Michalek-Zrabkowska, Monika and Mazur, Grzegorz and Wieckiewicz, Mieszko},
  journal={Journal of clinical medicine},
  volume={8},
  number={9},
  pages={1344},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{emodi2020temporomandibular,
  title={Temporomandibular disorders and bruxism outbreak as a possible factor of orofacial pain worsening during the COVID-19 pandemic—concomitant research in two countries},
  author={Emodi-Perlman, Alona and Eli, Ilana and Smardz, Joanna and Uziel, Nir and Wieckiewicz, Gniewko and Gilon, Efrat and Grychowska, Natalia and Wieckiewicz, Mieszko},
  journal={Journal of Clinical Medicine},
  volume={9},
  number={10},
  pages={3250},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{almeida2020psychosocial,
  title={How psychosocial and economic impacts of COVID-19 pandemic can interfere on bruxism and temporomandibular disorders?},
  author={Almeida-Leite, Camila Megale and Stuginski-Barbosa, Juliana and Conti, Paulo C{\'e}sar Rodrigues},
  journal={Journal of Applied Oral Science},
  volume={28},
  year={2020},
  publisher={SciELO Brasil}
}